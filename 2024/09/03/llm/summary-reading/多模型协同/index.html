<!DOCTYPE html>
<html lang="zh-cn,en,default">
<head>
  <meta charset="UTF-8">




<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, minimum-scale=1.0">
<meta http-equiv="X-UA-Compatible" content="ie=edge">

  <meta name="author" content="崔若晨 Ruochen Cui">


  <meta name="subtitle" content="崔若晨">


  <meta name="description" content="电子科技大学四年级本科生

A fourth year undergraduate student at UESTC
">


  <meta name="keywords" content="Ruochen Cui,崔若晨,Artificial Intelligence">


<title>LLM综述-多模型协同 | Ruochen Cui</title>



<link rel="icon" href="/web_ico.ico">


<script src="http://ajax.googleapis.com/ajax/libs/jquery/1.7.1/jquery.min.js" type="text/javascript"></script>
<link
  rel="stylesheet"
  href="https://cdn.jsdelivr.net/npm/katex/dist/katex.min.css"
/>
<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=Roboto:ital,wght@0,100;0,300;0,400;0,500;0,700;0,900;1,100;1,300;1,400;1,500;1,700;1,900&display=swap" rel="stylesheet">


<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/css/search.css">



<script src="/lib/jquery.min.js"></script>


<script src="/lib/iconify-icon.min.js"></script>


<script src="https://cdn.tailwindcss.com?plugins=typography"></script>
<script>
  tailwind.config = {
    darkMode: "class",
  };
</script>

<script>
  (function () {
    const prefersDark =
      window.matchMedia &&
      window.matchMedia("(prefers-color-scheme: dark)").matches;
    const setting = localStorage.getItem("hexo-color-scheme") || "auto";
    if (setting === "dark" || (prefersDark && setting !== "light"))
      document.documentElement.classList.toggle("dark", true);
    let isDark = document.documentElement.classList.contains("dark");
  })();

  $(document).ready(function () {
    // init icon
    const prefersDark =
      window.matchMedia &&
      window.matchMedia("(prefers-color-scheme: dark)").matches;
    const isDark = document.documentElement.classList.contains("dark");
    $("#theme-icon").attr("icon", isDark ? "ic:round-dark-mode" : "ic:round-light-mode");

    function toggleGiscusTheme() {
      const isDark = document.documentElement.classList.contains("dark");
      const giscusFrame = document.querySelector("iframe.giscus-frame");
      if (giscusFrame) {
        giscusFrame.contentWindow.postMessage(
          {
            giscus: {
              setConfig: {
                theme: isDark ? "dark" : "light",
              },
            },
          },
          "https://giscus.app"
        );
      }
    }


    // toggle dark mode
    function toggleDark() {
      let isDark = document.documentElement.classList.contains("dark");
      const setting = localStorage.getItem("hexo-color-scheme") || "auto";
      isDark = !isDark;
      document.documentElement.classList.toggle("dark", isDark);
      $("#theme-icon").attr("icon", isDark ? "ic:round-dark-mode" : "ic:round-light-mode");
      if (prefersDark === isDark) {
        localStorage.setItem("hexo-color-scheme", "auto");
      } else {
        localStorage.setItem("hexo-color-scheme", isDark ? "dark" : "light");
      }
      toggleGiscusTheme();
    }
    $("#toggle-dark").click(toggleDark);

    // listen dark mode change
    window
      .matchMedia("(prefers-color-scheme: dark)")
      .addEventListener("change", (e) => {
        const setting = localStorage.getItem("hexo-color-scheme") || "auto";
        if (setting === "auto") {
          document.documentElement.classList.toggle("dark", e.matches);
          $("#theme-icon").attr(
            "icon",
            e.matches ? "ic:round-dark-mode" : "ic:round-light-mode"
          );
          toggleGiscusTheme();
        }
      });
  });
</script>




<meta name="generator" content="Hexo 7.1.1"><link href="https://cdn.bootcss.com/KaTeX/0.11.1/katex.min.css" rel="stylesheet" /></head>
<body 
  class="
    bg-[var(--c-0)]
    text-[var(--c-80)]
  ">
  <!-- The navigation bar -->
<header class="
    flex flex-row items-center
    w-full
    pr-4
    z-10
    border-b-[1px]
    border-b-[var(--c-border)]
    dark:bg-[var(--c-0)]
    dark:border-b-[var(--c-0)]
    gap-2
    h-[var(--h-header)]
    text-[var(--c-80)]
">
  <!-- Left part -->
  <div class="overflow-hidden h-full flex flex-row items-center">
    <!-- Site Title on the top left -->
    <a href="/" class="
            whitespace-nowrap
            text-2xl
            text-[var(--c-theme)]
            hover:text-[var(--c-theme)]
            pl-4
            font-black
            bg-gradient-to-r from-cyan-500
            to-blue-500 bg-clip-text text-transparent
          ">
      Ruochen Cui
    </a>
  </div>
  <!-- Div for pushing items to both sides -->
  <div class="flex-1"></div>
  <!-- Right part -->
  <div class="flex flex-row items-center z-20 h-full">
    <!-- Page links -->
    <div class="hidden sm:flex flex-row h-full">
      
      
      
      
      
      
      <a href="/./archives" class="
                        flex flex-row items-center
                        gap-1
                        hover:underline
                        hover:bg-[var(--c-20)]
                        hover:text-[var(--c-theme)]
                        transition-all
                        px-2
                        py-1
                        my-1
                        rounded-lg
                        group
                    ">
        
        <iconify-icon class="group-hover:scale-125 transition-transform" icon="mingcute:inbox-fill" width="22">
        </iconify-icon>
        
        
        <p>Posts</p>
        
      </a>
      
      
      
      
      
      
      <a href="/./publications" class="
                        flex flex-row items-center
                        gap-1
                        hover:underline
                        hover:bg-[var(--c-20)]
                        hover:text-[var(--c-theme)]
                        transition-all
                        px-2
                        py-1
                        my-1
                        rounded-lg
                        group
                    ">
        
        <iconify-icon class="group-hover:scale-125 transition-transform" icon="mingcute:science-fill" width="22">
        </iconify-icon>
        
        
        <p>Publications</p>
        
      </a>
      
      
      
      
      
      
      <a href="/./about" class="
                        flex flex-row items-center
                        gap-1
                        hover:underline
                        hover:bg-[var(--c-20)]
                        hover:text-[var(--c-theme)]
                        transition-all
                        px-2
                        py-1
                        my-1
                        rounded-lg
                        group
                    ">
        
        <iconify-icon class="group-hover:scale-125 transition-transform" icon="mingcute:user-info-fill" width="22">
        </iconify-icon>
        
        
        <p>About</p>
        
      </a>
      
      
      
      
      
      
      <a href="/./categories" class="
                        flex flex-row items-center
                        gap-1
                        hover:underline
                        hover:bg-[var(--c-20)]
                        hover:text-[var(--c-theme)]
                        transition-all
                        px-2
                        py-1
                        my-1
                        rounded-lg
                        group
                    ">
        
        <iconify-icon class="group-hover:scale-125 transition-transform" icon="mingcute:classify-2-fill" width="22">
        </iconify-icon>
        
        
        <p>Categories</p>
        
      </a>
      
      
      
      
      
      
      <a href="/./tags" class="
                        flex flex-row items-center
                        gap-1
                        hover:underline
                        hover:bg-[var(--c-20)]
                        hover:text-[var(--c-theme)]
                        transition-all
                        px-2
                        py-1
                        my-1
                        rounded-lg
                        group
                    ">
        
        <iconify-icon class="group-hover:scale-125 transition-transform" icon="mingcute:tag-fill" width="22">
        </iconify-icon>
        
        
        <p>Tags</p>
        
      </a>
      
      
      
      
      
      
      <a href="/./index" class="
                        flex flex-row items-center
                        gap-1
                        hover:underline
                        hover:bg-[var(--c-20)]
                        hover:text-[var(--c-theme)]
                        transition-all
                        px-2
                        py-1
                        my-1
                        rounded-lg
                        group
                    ">
        
        <iconify-icon class="group-hover:scale-125 transition-transform" icon="mingcute:home-2-fill" width="22">
        </iconify-icon>
        
        
      </a>
      
    </div>
    <!-- Icons on the right -->
    <div class="flex flex-row items-center">

      <!-- TODO: Add search icon here -->

      <!-- Dark/light toggle icon -->
      <a class="flex group p-1" title="toggle theme" id="toggle-dark">
        <iconify-icon class="transition-transform
                    group-hover:rotate-[45deg]
                    group-hover:scale-125
                    group-hover:text-[var(--c-theme)]" width="24" id="theme-icon">
        </iconify-icon>
      </a>
      <!-- Icon for dropout menu on small screens -->
      <div class="flex p-1 mx-1 sm:hidden">
        <a class="w-5 h-5" aria-hidden="true" id="open-menu">
          <iconify-icon width="24" icon="mingcute:menu-fill" class="transition-transform hover:scale-125 hover:rotate-[5deg]">
          </iconify-icon>
        </a>
        <a class="w-5 h-5 hidden" aria-hidden="true" id="close-menu">
          <iconify-icon width="24" icon="mingcute:close-circle-fill" class="transition-transform hover:scale-125 hover:rotate-[80deg]">
          </iconify-icon>
        </a>
      </div>
    </div>
  </div>
</header>

<!-- Dropdown menu on small screens -->
<div id="menu-panel" class="
        h-0
        overflow-hidden
        sm:hidden
        w-full
        z-10
        rounded
    ">
  <div id="menu-content" class="
        flex
        flex-row
        justify-center
        items-center
        font-bold
        text-xl
        border-b-[1px]
        relative
        z-20
        border-[var(--c-sep)]
        px-2
        py-2
        -translate-y-full
        transition-transform
        duration-200
        ">
    
    
    
    <a href="/./archives" class="
                flex flex-row items-center
                gap-2
                h-12
                hover:underline
                hover:bg-[var(--c-20)]
                px-3
                py-1
                rounded-lg
            ">
      <iconify-icon icon="mingcute:inbox-fill" width="22">
      </iconify-icon>
      <p>
        posts
      </p>
    </a>
    
    
    
    
    <a href="/./publications" class="
                flex flex-row items-center
                gap-2
                h-12
                hover:underline
                hover:bg-[var(--c-20)]
                px-3
                py-1
                rounded-lg
            ">
      <iconify-icon icon="mingcute:science-fill" width="22">
      </iconify-icon>
      <p>
        publications
      </p>
    </a>
    
    
    
    
    <a href="/./about" class="
                flex flex-row items-center
                gap-2
                h-12
                hover:underline
                hover:bg-[var(--c-20)]
                px-3
                py-1
                rounded-lg
            ">
      <iconify-icon icon="mingcute:user-info-fill" width="22">
      </iconify-icon>
      <p>
        about
      </p>
    </a>
    
    
    
    
    <a href="/./categories" class="
                flex flex-row items-center
                gap-2
                h-12
                hover:underline
                hover:bg-[var(--c-20)]
                px-3
                py-1
                rounded-lg
            ">
      <iconify-icon icon="mingcute:classify-2-fill" width="22">
      </iconify-icon>
      <p>
        categories
      </p>
    </a>
    
    
    
    
    <a href="/./tags" class="
                flex flex-row items-center
                gap-2
                h-12
                hover:underline
                hover:bg-[var(--c-20)]
                px-3
                py-1
                rounded-lg
            ">
      <iconify-icon icon="mingcute:tag-fill" width="22">
      </iconify-icon>
      <p>
        tags
      </p>
    </a>
    
    
    
    
    <a href="/./index" class="
                flex flex-row items-center
                gap-2
                h-12
                hover:underline
                hover:bg-[var(--c-20)]
                px-3
                py-1
                rounded-lg
            ">
      <iconify-icon icon="mingcute:home-2-fill" width="22">
      </iconify-icon>
      <p>
        home
      </p>
    </a>
    
    
  </div>
</div>
  <main>
    <!-- css -->

<link rel="stylesheet" href="/lib/fancybox/fancybox.min.css">

  
<link rel="stylesheet" href="/lib/tocbot/tocbot.min.css">

    <!-- toc -->
    
  <!-- tocbot -->
<nav class="post-toc toc text-sm w-40 relative top-32 right-4 opacity-70 hidden lg:block" style="position: fixed !important;"></nav>


<section class="px-6 max-w-prose mx-auto md:px-0">
  <!-- Post header before content -->
  <header class="py-4">
    <div class="flex flex-col gap-2 pt-4 md:pt-6">
      <!-- Title -->
      <div id="article-title" class="leading-snug">
        <p class="text-3xl font-bold text-[var(--c-100)] mb-4">LLM综述-多模型协同</p>
      </div>
      <!-- Meta data -->
      <div>
        <section class="
          flex flex-col gap-x-2 gap-y-1 text-sm text-[var(--c-100)]">
          <div class="flex flex-wrap items-center gap-x-2 gap-y-1">
            <!-- Dates -->
            <div class="flex items-center gap-1">
              <iconify-icon width="18" icon="mingcute:add-circle-fill" ></iconify-icon>
              Created: <time class="w-max">2024-09-03</time>
            </div>
            <div class="flex items-center gap-1">
              <iconify-icon width="18" icon="mingcute:refresh-3-fill" ></iconify-icon>
              Edited: <time class="w-max">2024-10-14</time>
            </div>
          </div>
          <div class="flex flex-wrap items-center gap-x-3 gap-y-3">
            <!-- Author -->
            
              <span class="flex items-center gap-1 group">
                <iconify-icon width="18" icon="mingcute:user-edit-fill" ></iconify-icon>
                <p>myself</p>
              </span>
            

            <!-- Word count -->
            <span class="flex items-center gap-1">
              <iconify-icon width="18" icon="mingcute:book-2-fill" ></iconify-icon>
              <span>3.4k words, 12 min</span>
            </span>
            <!-- Categories -->
            
              <!-- <span class="text-gray-400">·</span> -->
              <span class="flex flex-row items-center gap-1 group hover:underline">
                <iconify-icon class="transition-all group-hover:scale-125 mr-0"
                  width="18"
                  icon="mingcute:classify-2-fill">
                </iconify-icon>
                <a class="article-category-link" href="/categories/%E7%A0%94%E7%A9%B6-%E5%A4%A7%E6%A8%A1%E5%9E%8B/">研究-大模型</a>
              </span>
            
          </div>
        </section>
      </div>
      <!-- tags -->
      <div>
        
<div class="flex flex-wrap gap-1">
  
    
      <a href="/tags/research/" 
        class="
          tag
          text-sm
          rounded-full
          px-[5px]
          border-[1px]
          border-[var(--c-theme)]
          text-[var(--c-theme)]
          bg-[var(--c-0)]
          dark:bg-[var(--c-0)]
          dark:drop-shadow-none
          hover:bg-[var(--c-theme)]
          hover:text-[var(--c-0)]
          dark:hover:text-[var(--c-theme-2)]
        ">
        research
      </a>
    
      <a href="/tags/llm/" 
        class="
          tag
          text-sm
          rounded-full
          px-[5px]
          border-[1px]
          border-[var(--c-theme)]
          text-[var(--c-theme)]
          bg-[var(--c-0)]
          dark:bg-[var(--c-0)]
          dark:drop-shadow-none
          hover:bg-[var(--c-theme)]
          hover:text-[var(--c-0)]
          dark:hover:text-[var(--c-theme-2)]
        ">
        llm
      </a>
    
      <a href="/tags/paper/" 
        class="
          tag
          text-sm
          rounded-full
          px-[5px]
          border-[1px]
          border-[var(--c-theme)]
          text-[var(--c-theme)]
          bg-[var(--c-0)]
          dark:bg-[var(--c-0)]
          dark:drop-shadow-none
          hover:bg-[var(--c-theme)]
          hover:text-[var(--c-0)]
          dark:hover:text-[var(--c-theme-2)]
        ">
        paper
      </a>
    
  
</div>
      </div>
    </div>
  </header>
  <!-- content -->
  <article class="post-content prose m-auto dark:prose-invert">
    <p><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2407.06089">Merge, Ensemble, and Cooperate! A Survey on Collaborative Strategies in the Era of Large Language Models</a></p>
<h1 id="Intro"><a href="#Intro" class="headerlink" title="Intro"></a>Intro</h1><ol>
<li><strong>Merging</strong>: Merging involves integrating multiple LLMs into a unified, stronger one, primarily through arithmetic operations in the model parameter space.</li>
<li><strong>Ensemble</strong>: Ensemble combines the outputs of different models to obtain coherent results.</li>
<li><strong>Cooperation</strong>: Cooperation is a relatively broad concept. This survey focuses on cooperation methods that leverage the diverse capabilities of different LLMs to accomplish specific objectives, such as efficient computation or knowledge transfer.</li>
</ol>
<p>这三种方法是由小到大要求逐渐宽松的</p>
<h1 id="Background"><a href="#Background" class="headerlink" title="Background"></a>Background</h1><p>针对 pre-trained language model (PLMs), 大多数模型使用 causal language modeling (逐 token 预测)</p>
<p>finetuning 阶段, 大多数采用 RLHF 技术 (InstructGPT), 但是存在 RLHF 后模型效果变差的情况</p>
<h2 id="Emergent-Abilities"><a href="#Emergent-Abilities" class="headerlink" title="Emergent Abilities"></a>Emergent Abilities</h2><p>语言模型的基础是文本生成, 自回归生成 tokens</p>
<p>In-Context-Learning (ICL): 为了更好完成任务</p>
<script type="math/tex; mode=display">
p(\mathbf{y}|\mathbf{x}) = p(\mathbf{y}|\mathbf{x},\mathrm{demonstration}(\{\mathbf{x}_i, \mathbf{y}_i  \}^k_{i=1}))</script><p>Instruction Following (指令微调): 为了更好地提升多任务泛化性, 这里 $\mathcal{L}$ 是当前样本的指令</p>
<script type="math/tex; mode=display">
p(\mathbf{y}|\mathbf{x}) = p(\mathbf{y}|\mathbf{x}, \mathcal{L})</script><h2 id="Collaboration-for-LLMs"><a href="#Collaboration-for-LLMs" class="headerlink" title="Collaboration for LLMs"></a>Collaboration for LLMs</h2><h1 id="Merging"><a href="#Merging" class="headerlink" title="Merging"></a>Merging</h1><p>模型融合主要关注两个问题</p>
<ol>
<li><p>M-ROS: merging to approch a relatively optimal solution</p>
<p> 梯度优化的最优值往往在梯度变化最小的地方 (DLFC 里的图)</p>
</li>
<li><p>M-MTC: multi-task capability</p>
<p> 让单个模型具有多个模型在多任务上的良好性能</p>
</li>
</ol>
<p>以上这两种模型合并方法仅适用于具有相同架构的模型</p>
<h2 id="Merging-for-Relatively-Optimal-Solution-M-ROS"><a href="#Merging-for-Relatively-Optimal-Solution-M-ROS" class="headerlink" title="Merging for Relatively Optimal Solution (M-ROS)"></a>Merging for Relatively Optimal Solution (M-ROS)</h2><p>深度学习模型难以达到最优解, 既有研究指出参数平均可以平衡不同的局部最优解, 整合不同模型的优势, 减少单个模型的偏差和方差. 这些方法主要分为两类, 简单平均和加权平均</p>
<h3 id="Basic-M-ROS-Methodologies"><a href="#Basic-M-ROS-Methodologies" class="headerlink" title="Basic M-ROS Methodologies"></a>Basic M-ROS Methodologies</h3><p>以下是一些 pre-LLM 时代的模型融合方法</p>
<h4 id="Simple-Average"><a href="#Simple-Average" class="headerlink" title="Simple Average"></a>Simple Average</h4><p>推理时进行暴力参数求平均</p>
<ol>
<li><p>Model Soup (2022) 提出了 Uniform Soup 和 Greedy Soup</p>
<ol>
<li><p>Uniform Soup: 简单地平均模型参数</p>
</li>
<li><p>Greedy Soup: 逐个添加模型到集合中, 确保每个新模型都能得到效果提升</p>
</li>
</ol>
</li>
<li><p>DiWA (2022) 利用候选模型在验证集上的表现进行排序, 有性能提升时才进行参数平均.</p>
</li>
</ol>
<h4 id="Weighted-Average"><a href="#Weighted-Average" class="headerlink" title="Weighted Average"></a>Weighted Average</h4><p>推理时进行加权平均</p>
<ol>
<li><p>Learned Soup (2022) 在验证集上优化混合系数来最小化损失函数</p>
</li>
<li><p>利用 Fisher 信息矩阵来衡量使用不同随机种子微调模型参数的重要性</p>
</li>
<li><p>基于几何关系, 根据参数间的角度偏差来插值微调模型</p>
</li>
</ol>
<h3 id="Adaptation"><a href="#Adaptation" class="headerlink" title="Adaptation"></a>Adaptation</h3><p>在大模型时代的方法</p>
<h4 id="Acquiring-Stronger-LLMs"><a href="#Acquiring-Stronger-LLMs" class="headerlink" title="Acquiring Stronger LLMs"></a>Acquiring Stronger LLMs</h4><p>基于微调前后参数矩阵的变化率来计算合并系数</p>
<ol>
<li><p>利用预训练过程中的 checkpoint, 结合贝叶斯优化来搜索最优合并系数</p>
</li>
<li><p>模型不同层分配不同的合并系数</p>
</li>
<li><p>先使用不同的指令调优数据训练多个子模型, 然后合并大模型</p>
</li>
</ol>
<h4 id="Enhancing-RLHF"><a href="#Enhancing-RLHF" class="headerlink" title="Enhancing RLHF"></a>Enhancing RLHF</h4><p>以下是一些在 RLHF 上的合并方法</p>
<ol>
<li><p>为了模型不同层分配不同的合并系数</p>
</li>
<li><p>微调多个 reward model, 平均参数</p>
</li>
<li>SFT 期间加权平均来提高 LLM 与人类偏好的对齐效果, 减少数据偏差的影响</li>
</ol>
<h2 id="Merging-for-Enhancing-Multi-Task-Capability-M-MTC"><a href="#Merging-for-Enhancing-Multi-Task-Capability-M-MTC" class="headerlink" title="Merging for Enhancing Multi-Task Capability (M-MTC)"></a>Merging for Enhancing Multi-Task Capability (M-MTC)</h2><p>实现具有不同能力的模型的平衡融合, 得到能处理多个任务的单一模型. 早期研究聚焦于使用不同的合并系数, 当前研究倾向于根据任务特点进行灵活合并. 近期还有使用 incremental learning (增量学习) 技术来提升性能的工作</p>
<h3 id="Methods-based-on-Weighted-Average"><a href="#Methods-based-on-Weighted-Average" class="headerlink" title="Methods based on Weighted Average"></a>Methods based on Weighted Average</h3><ol>
<li>RegMean: 选择性整合线性层, 对其他层采用简单平均</li>
<li>从黑塞矩阵得到的估计值来进行加权平均</li>
<li>Fisher 加权平均和模型剪枝结合</li>
</ol>
<h3 id="Methods-based-on-task-Property"><a href="#Methods-based-on-task-Property" class="headerlink" title="Methods based on task Property"></a>Methods based on task Property</h3><p>基于加权平均的融合方法强调了参数的重要性, 但忽略了任务本身的特点, 导致某些任务重性能下降. 既有研究指出, 简单平均会导致 10% 的性能下降, 近期研究引入了一种名为任务向量的新范式</p>
<p>任务向量 (Task Property): 一个参数空间中的向量, 指定了预训练模型参数空间中的移动方向, 参数在该方向上的移动能提升任务性能</p>
<script type="math/tex; mode=display">
\tau_t = \theta^{\mathrm{ft}} - \theta^{\mathrm{pre}}</script><p>这里 $\theta^{\text{ft}}$ 是在特定任务 $t$ 上微调后的参数, $\theta^{\text{pre}}$ 是预训练模型原本的参数</p>
<p>任务向量在模型合并的过程中能更有效地解决参数冲突</p>
<blockquote>
<p>参数冲突: 当不同模型的参数向量在同一参数上方向相反时, 冲突发生</p>
<p><img src="https://cdn.jsdelivr.net/gh/421zuoduan/blog-imgs@main/imgs/image-20240903165121491.png" alt="任务向量与参数冲突"></p>
</blockquote>
<p>近期的工作致力于缓解冲突和平衡不同模型. 一部分参数冲突方法在参数位置解决冲突, 还有一部分工作识别并去除参数来减少冲突. </p>
<h4 id="Resolving-Parameter-Conflicts"><a href="#Resolving-Parameter-Conflicts" class="headerlink" title="Resolving Parameter Conflicts"></a>Resolving Parameter Conflicts</h4><ol>
<li>task arithmetic (2023) 最初通过微调参数和预训练参数的差异来推导任务向量</li>
<li>Ties-Merging: 分析冲突产生的两个原因, 荣誉参数和模型间的符号冲突</li>
<li>AdaMerging: 考虑不同模型参数的重要性</li>
<li>基于 AdaMerging 和 task arithmetic 的高效方法</li>
<li>在参数空间中使用 TieMerging 合并参数, 并使用进化算法优化合并模型内部的数据推理路径</li>
</ol>
<p>ZipIt: 没有使用任务向量, 从另一个角度保留相似参数. 首先找到模型间高度相关的参数, 合并这些参数的同时保留显著不同的层, 提高合并的灵活性</p>
<h4 id="Pruning-Redundant-Parameters"><a href="#Pruning-Redundant-Parameters" class="headerlink" title="Pruning Redundant Parameters"></a>Pruning Redundant Parameters</h4><p>通过剪枝可以去掉一些冲突参数</p>
<ol>
<li>DARE (2023): 丢弃或缩放参数来减少冗余参数的技术. 但是模型泛化性较差</li>
<li>DELLA-Merging (2024): 在 DARE 基础上选择重要参数进行融合</li>
<li>DPPA (动态剪枝, 分区放大)</li>
</ol>
<h4 id="Toolkit"><a href="#Toolkit" class="headerlink" title="Toolkit"></a>Toolkit</h4><p>一个开源工具包, 集成了多种模型合并方法</p>
<h3 id="Methods-based-on-Incremental-Training"><a href="#Methods-based-on-Incremental-Training" class="headerlink" title="Methods based on Incremental Training"></a>Methods based on Incremental Training</h3><p>前述方法不同程度地存在效果下降的问题</p>
<p>Concrete TA/AM (2023): 在参数空间内找一个共享的低维子空间, 最小化任务间的干扰</p>
<p>Surgery (2024): 引入一种表征修正技术, 缓解多任务模型融合中的表征偏差</p>
<h1 id="Ensemble"><a href="#Ensemble" class="headerlink" title="Ensemble"></a>Ensemble</h1><p>传统的机器学习中集成学习有 Adaboost, Bagging, Stacking</p>
<h2 id="LLM-Ensemble-Methodology"><a href="#LLM-Ensemble-Methodology" class="headerlink" title="LLM Ensemble Methodology"></a>LLM Ensemble Methodology</h2><p>LLM 生成 token 输出, 这种输出是离散的, 且 LLM 间的结构差异使得词汇和输出分布难以统一, 复杂了集成策略</p>
<p>一般在推理过程中进行模型集成, 所以这里氛围推理前, 推理中和推理后进行介绍. 一般而言</p>
<ol>
<li>推理前: 不同输入选择不同 LLM</li>
<li>推理中: 在每个解码步骤中合并输出</li>
<li>推理后: 从多个 LLM 输出中选择最佳的输出</li>
</ol>
<h3 id="Ensemble-Before-Inference"><a href="#Ensemble-Before-Inference" class="headerlink" title="Ensemble Before Inference"></a>Ensemble Before Inference</h3><p>根据不同输入选择不同 LLM (路由, 和 MoE 类似), 这些工作是从 23 年 9 月开始的</p>
<ol>
<li>用 benchmark datasets 训练了路由 (router)</li>
<li>Zooter (2023): 用 reward model 计算训练集中 query-output 对的分数, 然后蒸馏训练路由器, 使其仅根据 Q 查找最佳 LLM</li>
<li>根据 Q 的难度分给小模型或 LLM</li>
<li>基于分类器和基于聚类的路由方法</li>
<li>受 RL 启发, 循环利用自生成的三元组 (查询, 响应, 分数) 来训练路由器</li>
<li>对话中每轮随机选择一个 LLM</li>
<li>RouteBench: 评估路由器的能力和局限性</li>
</ol>
<h3 id="Ensemble-During-Inference"><a href="#Ensemble-During-Inference" class="headerlink" title="Ensemble During Inference"></a>Ensemble During Inference</h3><p>大模型自回归的特性导致后面的 token更可能出错</p>
<p>一些工作在解码中加入 LLM, 要求词汇表相同, 这确保了输出分布的对齐, 能够有效集成</p>
<ol>
<li>加权平均输出, 将不可信的 LLM 和一个良性的小型 LLM 结合</li>
<li>对机器翻译模型和 LLM 中的输出分布插值, 提升翻译性能</li>
<li>“节俭专家融合”问题, 转换为图的最短路径问题</li>
</ol>
<p>然而, 大多数开源模型都是异构且词汇表不同的, 基于此</p>
<ol>
<li>(没看懂) 作了 token alignment</li>
<li>将上面的严格匹配限制改为最小距离限制</li>
<li>提出利用困惑度 (perplexity) 来计算集成系数</li>
<li>一些工作将多个模型回答中重复出现的 token 作为锚点, 将异构 LLM 产生的输出分布投影到同一空间<ol>
<li>直接利用锚点, 学习不同词汇间的投影矩阵</li>
<li>计算锚点到不同词汇的相同表示, 间接实现词汇投影</li>
</ol>
</li>
</ol>
<h3 id="Ensemble-After-Inference"><a href="#Ensemble-After-Inference" class="headerlink" title="Ensemble After Inference"></a>Ensemble After Inference</h3><p>多个 LLM 级联</p>
<ol>
<li>用多个按参数数量排序的 LLM 级联来生成输出, 前序较小 LLM 产生质量足够好的输出时返回结果</li>
<li>先验证较小 LLM 生成答案的正确性, 初始答案不正确时使用更大的 LLM</li>
</ol>
<p>从多个 LLM 答案中选最好的</p>
<ol>
<li>选择最佳指令, 构建指令调优数据</li>
<li>无监督选择指标, 如 BERTScore, BLEURT, BARTScore 和ChatGPT 评分</li>
<li>用一个额外的融合模型, 利用排名最高的候选答案作为输入, 得到最终输出</li>
</ol>
<h3 id="Discussion-about-LLM-Ensumble-Methods"><a href="#Discussion-about-LLM-Ensumble-Methods" class="headerlink" title="Discussion about LLM Ensumble Methods"></a>Discussion about LLM Ensumble Methods</h3><p>以下从推理速度, 集成粒度和局限性三个方面讨论</p>
<h4 id="Inference-Speed"><a href="#Inference-Speed" class="headerlink" title="Inference Speed"></a>Inference Speed</h4><p>所有的集成方法都会造成推理速度的下降. 时间上 Before&lt;During&lt;After</p>
<h4 id="Ensemble-Granularity"><a href="#Ensemble-Granularity" class="headerlink" title="Ensemble Granularity"></a>Ensemble Granularity</h4><p>Before 和 After 是在样本的粗粒度上集成, During 是在 token 的细粒度上集成. 由于自回归的性质, 细粒度的方法能够减少 曝光偏差 (exposure bias), 减少幻觉</p>
<h4 id="Limitations"><a href="#Limitations" class="headerlink" title="Limitations"></a>Limitations</h4><ol>
<li>推理前: 路由器会限制集成方法的能力</li>
<li>推理中: 受限于大模型的异构架构, 词汇差异可能导致输出分布不对应</li>
<li>推理后: 候选答案的准确性和选择策略</li>
</ol>
<h2 id="LLM-Ensemble-Application"><a href="#LLM-Ensemble-Application" class="headerlink" title="LLM Ensemble Application"></a>LLM Ensemble Application</h2><h3 id="LLM-Emsemble-for-Specific-Tasks-or-Domains"><a href="#LLM-Emsemble-for-Specific-Tasks-or-Domains" class="headerlink" title="LLM Emsemble for Specific Tasks or Domains"></a>LLM Emsemble for Specific Tasks or Domains</h3><ol>
<li>训练分类器, 选择不同的 LLM 专家生成最佳答案</li>
<li>SQL 生成</li>
<li>Medical</li>
<li>临床文本错误检测与纠正</li>
<li>多数投票和平均甲醛来选择最常出现的疾病</li>
</ol>
<h3 id="LLM-Ensemble-for-Overestimation-Mitigation-in-RLHF"><a href="#LLM-Ensemble-for-Overestimation-Mitigation-in-RLHF" class="headerlink" title="LLM Ensemble for Overestimation Mitigation in RLHF"></a>LLM Ensemble for Overestimation Mitigation in RLHF</h3><p>缓解 LLM 的校准不良和预测不可靠问题</p>
<ol>
<li>多个 reward model 集成来缓解过度优化问题</li>
<li>轻量级 LoRA 来适应多个奖励模型</li>
<li>使用共享 LLM, 但是各个头独立进行 reward 集成</li>
</ol>
<h1 id="Cooperation"><a href="#Cooperation" class="headerlink" title="Cooperation"></a>Cooperation</h1><p>LLM Cooperation 主要关注高效计算, 知识传递, 补偿性合作, 联邦合作</p>
<h2 id="Efficient-Computation"><a href="#Efficient-Computation" class="headerlink" title="Efficient Computation"></a>Efficient Computation</h2><p>模型加速还可分为输入压缩 (Input Compression) 和 推测性解码 (Speculative Decoding)</p>
<h3 id="Input-Compression"><a href="#Input-Compression" class="headerlink" title="Input Compression"></a>Input Compression</h3><p>利用额外的模型去除冗余 token 或压缩 token 长度. 以下三种类型的方法压缩率逐渐增加, 效率也逐渐增加, 但是信息损失也更多</p>
<h4 id="Prompt-Pruning"><a href="#Prompt-Pruning" class="headerlink" title="Prompt Pruning"></a>Prompt Pruning</h4><p>核心思想: 根据 token 的重要性度量, 减少输入 token 长度. Cooperation model 用于剪枝</p>
<ol>
<li>利用 Prompt 得到图, 通过图进行压缩</li>
<li>LLMLingua-2 (2024) 蒸馏方法, 利用 Transformer 的 Encoder 对输入 token 分类, 保留分类概率最高的 N 个 token, 去除其他 token</li>
<li>从粗粒度到细粒度的剪枝方法, 在大规模样本中找到关键的有关 CoT 的 token, 然后去除不重要的 token</li>
</ol>
<h4 id="Prompt-Summarization"><a href="#Prompt-Summarization" class="headerlink" title="Prompt Summarization"></a>Prompt Summarization</h4><p>核心思想: 利用 cooperation model, 将输入压缩成一个更短的 summary</p>
<blockquote>
<p>这里提到 extractive or abstractive summarization model, 推测前者是从既有文本中抽取, 后者是 cooperation model 自己总结</p>
</blockquote>
<ol>
<li>训练摘要模型来压缩上下文</li>
<li>删除语义影响较小的词语来减少 token (?, 有什么区别吗)</li>
<li>RECOMP (2023) 引入一个 abstractive compressor, 以问题和检索到的文档为输入, , 生成一个简要的摘要, 然后 LLM 基于摘要生成答案</li>
<li>SemanticCompression (2023) 将文本分成多个句子, 按主题队句子分类, 然后使用预训练模型对每个组摘要, 最后 LLM 摘要回答</li>
</ol>
<h4 id="Soft-Prompt-Compression"><a href="#Soft-Prompt-Compression" class="headerlink" title="Soft Prompt Compression"></a>Soft Prompt Compression</h4><p>使用 virtual token 来辅助压缩, cooperation 是文本特征编码器</p>
<ol>
<li><p>SelfCO (2024) 使用冻结 LLM 编码与解码, 在 prompt 中加入一些特殊 token 得到 virtual token (类似 Prompt Tuning), 从而实现 prompt compression 和答案生成 (?, 像是用额外的 token 辅助压缩, 没有讲具体的方法)</p>
</li>
<li><p>训练中使用 LLM 将 demonstration 映射到 virtual token, 然后根据语义相似性选择 demonstration, 最后使用冻结的 LLM 生成回答</p>
<blockquote>
<p>demonstration 推测是压缩后的信息, 相当于将 prompt 信息压缩到 virtual token 里, 而不是后者仅起辅助作用</p>
</blockquote>
</li>
</ol>
<h3 id="Speculative-Decoding"><a href="#Speculative-Decoding" class="headerlink" title="Speculative Decoding"></a>Speculative Decoding</h3><p>Speculative Decoding (推测性解码): 小模型生成 draft, 大模型验证, 从而提高推理速度. 生成 draft 的策略主要包括 Independent Drafting 和 Self-Drafting, 验证的策略主要包括 Greedy Decoding 和 Nucleus Sampling (2020, 也称核采样). 推测性解码的加速效果很大程度上取决于小模型生成 token 接受率</p>
<ol>
<li>在生成 draft token 过程中使用基于上下文的自适应 N-gram LLM 模型, 验证阶段则使用没有 N-gram 的 LLM 验证 (保持了同一个 LLM 的一致性)</li>
<li>早停, 如预测生成 token 的被接受率, 根据预定义阈值决定是否继续生成 </li>
</ol>
<h2 id="Knowledge-Transfer-via-Cooperation"><a href="#Knowledge-Transfer-via-Cooperation" class="headerlink" title="Knowledge Transfer via Cooperation"></a>Knowledge Transfer via Cooperation</h2><p>一般认为, LLM 的 logits 可以反应模型的知识. 近期大模型的知识迁移主要关注推理阶段的合作, 不涉及训练过程. 根据迁移的目标分类, 可以分成</p>
<ol>
<li>缓解错误知识</li>
<li>强化正确知识</li>
<li>提供新知识</li>
</ol>
<h3 id="Mitigating-Incorrect-Knowledge"><a href="#Mitigating-Incorrect-Knowledge" class="headerlink" title="Mitigating Incorrect Knowledge"></a>Mitigating Incorrect Knowledge</h3><p>有人认为自回归的训练方法存储的是 superficial partterns (表面模式), 而不是真实世界知识. 因此, 也有很多研究探索去除 logtis 中的错误知识的合作方法</p>
<script type="math/tex; mode=display">
y_i\sim \log \underbrace{p_{\rm{LLM}}(y_i|y_{<i})}_{\text{vanilla distribution}}-\underbrace{\log p_{\rm{AMA}}(y_i|y_{<i})}_{\text{amateur distribution}}</script><ol>
<li>较大的 LLM 的缺点在较小的 LLM 上同样存在且更明显, 基于此提出对比解码 (Contrastive Decoding, CD), 根据两个 LLM 的输出差异来消除输出分布上的错误知识</li>
<li>在第一篇工作的基础上, 减少了一些抽象推理的错误 (?)</li>
<li>在第一篇的基础上, 相对不好的, 业余的模型通过蒸馏得到</li>
<li>基于对比解码进行可信生成, 如机器翻译中的幻觉问题, 语言净化和情感控制生成</li>
<li>使用错误的样本进行微调, 诱导 LLM 生成幻觉内容, 将该模型用作业余模型</li>
<li>反事实对比解码, 生成干扰项</li>
<li>不同路由策略的 MoE 模型的输出分布差异显著, 利用没有选到的专家作为业余模型</li>
<li>对比解码与推测解码 (speculative decoding) 结合</li>
</ol>
<p>以上基于 Contrastive Decoding 的方法需要保证 LLM 与其业余模型属于同一类别, 输出分布要对齐</p>
<h3 id="Strengthening-Correct-Knowledge"><a href="#Strengthening-Correct-Knowledge" class="headerlink" title="Strengthening Correct Knowledge"></a>Strengthening Correct Knowledge</h3><p>使用 LLM 合作来提高正确答案生成的概率, 这一研究方向大多与控制文本生成的研究有关, 还有一些与贝叶斯分解有关的工作</p>
<script type="math/tex; mode=display">
p(y_i|y_{<i}, c)\propto p(y_i|y_{<i})\cdotp(c|y_i, y_{<i})\\

y_i\sim \log \underbrace{p_{\rm{LLM}}(y_i|y_{<i})}_{\text{vanilla distribution}}+\log \underbrace{p_{\text{VER}}(y_i|y_{<i})}_{\text{verification}}</script><p>这里 $c$ 是 input attribute (输入属性) (应该就是控制的想要生成的方向的 prompt)</p>
<p><img src="https://cdn.jsdelivr.net/gh/421zuoduan/blog-imgs@main/imgs/image-20240909145747319.png" alt="verification 的核心思想"></p>
<ol>
<li>使用一个辅助的 reward model 作为 verification, 控制 LLM 生成文本</li>
<li>根据语言生成任务的方程 (上面公式第二行), 验证每个 token, 提升 faithfulness</li>
<li>DIVER (2024), 使用 dynamic token span 来计算 point-wise mutual information (互信息, PMI), 用以验证. 这项工作在使用较小的 LLM 验证时环节了推理速度的下降</li>
</ol>
<h3 id="Supplying-New-Knowledge"><a href="#Supplying-New-Knowledge" class="headerlink" title="Supplying New Knowledge"></a>Supplying New Knowledge</h3><p>一些研究表明,  output logits 反应了 LLM 能力的变化. 一些工作通过修改 logits 使模型获取新能力</p>
<script type="math/tex; mode=display">
\log p_{\text{LARGE-C}}(y_i|y_{<i})\propto \underbrace{\log p_{\text{LARGE}}(y_i|y_{<i})}_{\text{vanilla distribution}} + \underbrace{[\log p_{\text{SMALL-C}}(y_i|y_{<i})-\log p_{\text{SMALL}(y_i|p_{<i})}]}_{\text{capability reflection}}</script><p>带有 $-\text{C}$ 的是具有特定能力的模型, 否则为原始模型</p>
<ol>
<li>emulated tuning 模拟调优, 从较小的 LLM 中提取 Chat 能力, 将该能力整合到较大的 LLM 上</li>
<li>proxy tuning 代理调优, 同 1</li>
<li>用安全/非安全的小模型来对抗性地修改一个更大的安全模型的解码概率, 从而实现对 LLM 的越狱</li>
</ol>
<p>以上的方法要求大小 LLM 有相同的词汇表. 在有不同的词汇表时, 有人引入了从弱到强的搜索, 利用小型微调和未微调 LLM 间的对数似然差异作为 reward, 树搜索指导解码, 减轻了相同词汇表的要求 (实现词汇表&lt;—-&gt; logits 的转变)</p>
<h2 id="Compensatory-Cooperation"><a href="#Compensatory-Cooperation" class="headerlink" title="Compensatory Cooperation"></a>Compensatory Cooperation</h2><p>引入额外的控制器, 可以用作 detector 或 retriever</p>
<h3 id="Factual-Hallucination"><a href="#Factual-Hallucination" class="headerlink" title="Factual Hallucination"></a>Factual Hallucination</h3><p>主流的事实幻觉检测方法分为</p>
<ol>
<li>检索外部事实: 模型生成的内容与外部知识源比较来识别事实性错误. LLM 的合作是这一种</li>
<li>不确定性估计: 依赖内部知识环节幻觉</li>
</ol>
<p>在第一类中主要有以下工作</p>
<ol>
<li>RARR (2022), 利用自然语言推理模型来评估 generated sentences 和 evidence 的事实一致性</li>
<li>考虑某些证据不完全支持某一主张, Factcheck 识别 evidence 并收集相关的其他 evidence, 然后使用 RARR 来证明</li>
</ol>

  </article>

  <!-- prev and next -->
  <div class="flex justify-between mt-4 pt-4
    border-t border-[var(--c-sep)] text-sm
    gap-2 text-[var(--c-50)]
  ">
    <div>
      
        <a href="/2024/09/07/llm/CCL%E8%AE%B2%E4%B9%A0%E7%8F%AD/"
          class="
            transition-all
            flex justify-center
            hover:-translate-x-1
            hover:text-[var(--c-80)]
          ">
          <iconify-icon width="20" icon="mingcute:left-fill" data-inline="false">
          </iconify-icon>
          CCL2024-前沿技术讲习班笔记
        </a>
      
    </div>
    <div>
      
        <a href="/2024/08/28/Article/2024/%E6%B4%BB%E5%9C%A8%E8%BF%99%E7%8F%8D%E8%B4%B5%E7%9A%84%E4%BA%BA%E9%97%B4/"
          class="
            flex 
            justify-center
            hover:translate-x-1 
            transition-transform
            hover:text-[var(--c-100)]
          "
        >
          活在这珍贵的人间
          <iconify-icon width="20" icon="mingcute:right-fill" data-inline="false"></iconify-icon>
        </a>
      
    </div>
  </div>

  <!-- comment -->
  <div class="article-comments mt-12">
    
  <script src="https://giscus.app/client.js"
  data-repo="421zuoduan/blog-giscus-discussion"
  data-repo-id="R_kgDONKEKag"
  data-category="Announcements"
  data-category-id="DIC_kwDONKEKas4Cj9R8"
  data-mapping="pathname"
  data-strict="0"
  data-reactions-enabled="1"
  data-emit-metadata="1"
  data-input-position="top"
  data-theme="preferred_color_scheme"
  data-lang="zh-CN"
  data-loading="lazy"
  crossorigin="anonymous"
  async>
</script>
<script>
  window.onload = function () {
    console.log("giscus loaded");
    const isDark = document.documentElement.classList.contains("dark");
    const giscusFrame = document.querySelector("iframe.giscus-frame");
    giscusFrame.contentWindow.postMessage(
      {
        giscus: {
          setConfig: {
            theme: isDark ? "dark" : "light",
          },
        },
      },
      "https://giscus.app"
    );
  };
</script>


  </div>
</section>
<!-- js inspect -->

<script src="/lib/clipboard.min.js"></script>


<script async src="https://cdn.jsdelivr.net/npm/mathjax@2/MathJax.js?config=TeX-MML-AM_CHTML"></script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    "HTML-CSS": {
        preferredFont: "TeX",
        availableFonts: ["STIX","TeX"],
        linebreaks: { automatic:true },
        EqnChunk: (MathJax.Hub.Browser.isMobile ? 10 : 50)
    },
    tex2jax: {
        inlineMath: [ ["$", "$"], ["\\(","\\)"] ],
        processEscapes: true,
        ignoreClass: "tex2jax_ignore|dno",
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
        equationNumbers: { autoNumber: "AMS" },
        noUndefined: { attributes: { mathcolor: "red", mathbackground: "#FFEEEE", mathsize: "90%" } },
        Macros: { href: "{}" }
    },
    messageStyle: "none"
  });
</script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
      var all = MathJax.Hub.getAllJax(), i;
      for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
      }
  });
</script>



<script src="https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js"></script>
<script>
  $(document).ready(() => {
    const maraidConfig = {
      theme: "default",
      logLevel: 3,
      flowchart: { curve: "linear" },
      gantt: { axisFormat: "%m/%d/%Y" },
      sequence: { actorMargin: 50 },
    };
    mermaid.initialize(maraidConfig);
  });
</script>



<script src="/lib/fancybox/fancybox.umd.min.js"></script>

<script>
  $(document).ready(() => {
    $('.post-content').each(function(i){
      $(this).find('img').each(function(){
        if ($(this).parent().hasClass('fancybox') || $(this).parent().is('a')) return;
        var alt = this.alt;
        var title = this.title;
        if (alt) $(this).after('<span class="fancybox-alt">' + alt + '</span>');
        if (title) $(this).after('<span class="fancybox-title">' + title + '</span>');
        $(this).wrap('<a class="fancybox-img" href="' + this.src + '" data-fancybox=\"gallery\" data-caption="' + alt + '"></a>')
      });
      $(this).find('.fancybox').each(function(){
        $(this).attr('rel', 'article' + i);
      });
    });

    Fancybox.bind('[data-fancybox="gallery"]', {
        // options
    })
  })
</script>

<!-- tocbot begin -->

<script src="/lib/tocbot/tocbot.min.js"></script>

<script>
  $(document).ready(() => {
      tocbot.init({
        // Where to render the table of contents.
        tocSelector: '.post-toc',
        // Where to grab the headings to build the table of contents.
        contentSelector: '.post-content',
        // Which headings to grab inside of the contentSelector element.
        headingSelector: 'h1, h2, h3',
        // For headings inside relative or absolute positioned containers within content.
        hasInnerContainers: true,
    });
  })
</script>
<!-- tocbot end -->

  </main>
  <footer class="flex flex-col mt-18 mb-12 items-center
  text-[var(--c-50)] text-sm">
  <div class="flex flex-row items-center my-12">
    
    
        
        
            
            
        
        <a class="
            hover:text-[var(--c-theme)]
            hover:bg-[var(--c-20)]
            rounded-lg
            p-2
            my-1
            flex flex-row items-center
            group" title="Github" target="_blank" rel="noopener" href="https://www.github.com/421zuoduan">
            <iconify-icon width="28" icon="mingcute:github-fill"></iconify-icon>
        </a>
    
        
        
            
            
        
        <a class="
            hover:text-[var(--c-theme)]
            hover:bg-[var(--c-20)]
            rounded-lg
            p-2
            my-1
            flex flex-row items-center
            group" title="ZhiHu" target="_blank" rel="noopener" href="https://www.zhihu.com/people/ren-jian-lan-xue">
            <iconify-icon width="28" icon="ri:zhihu-line"></iconify-icon>
        </a>
    

  </div>
  <!-- busuanzi -->
  <div class="mb-6">
    
<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
<!-- Busuanzi Analytics -->
<div class="flex flex-col items-center mb-2">
  <div class="flex flex-row items-center">
    <iconify-icon width="16" icon="ic:round-person" width="18"></iconify-icon>
    <span class="mr-1">访客 Visitors: </span>
    <span id="busuanzi_value_site_uv"></span>
  </div>
  <div class="flex flex-row items-center">
    <iconify-icon width="16" icon="carbon:view-filled" width="18"></iconify-icon>
    <span class="mx-1">浏览量 Page Views:</span>
    <span id="busuanzi_value_site_pv"></span>
  </div>
</div>
<!-- End Busuanzi Analytics -->


  </div>
  <!-- copyright -->
  <div class="flex flex-row items-center gap-2">
    <a class="hover:underline"
      target="_blank"
      href="https://creativecommons.org/licenses/by-nc-sa/4.0/"
    >
      CC BY-NC-SA 4.0
    </a>
    <span>© 2022-2024</span>
    <a class="hover:underline"
    href="https://github.com/chen-yingfa" 
    target="_blank" 
    rel="noopener noreferrer">陈英发</a>
  </div>
  <!-- powered by -->
  <div class="flex items-center gap-1">
    <span>Powered by</span>
    <a class="hover:underline" 
    href="https://hexo.io/" target="_blank" rel="noopener noreferrer">Hexo</a>
    <span>&</span>
    <a href="https://github.com/chen-yingfa/hexo-theme-fengye" 
    class="hover:underline"
    target="_blank"
      rel="noopener noreferrer"
      >
      枫叶 Fengye
    </a>
  </div>

</footer>

  <div class="
    back-to-top
    fixed right-6
    z-1024
    -bottom-20
    rounded-lg
    font-bold
    py-1 px-2
    text-[var(--c-80)]
    bg-[var(--c-20)]
    cursor-pointer
    text-center
    drop-shadow-md
  ">
    <span class="flex justify-center items-center text-sm">
      <span id="scrollpercent"><span>0</span> %</span>
      <iconify-icon width="18" icon="mingcute:arrow-to-up-fill" id="go-top"></iconify-icon>
    </span>
  </div>
  
<script src="/js/main.js"></script>


  <div class="fixed top-0 bottom-0 left-0 right-0 pointer-events-none print:hidden" id="maple"></div>
</body>

</html>
